{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from chardet import detect\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "from keras_bert import Tokenizer as k_Tokenizer\n",
    "import os\n",
    "\n",
    "def bert_text_model(seq_length,bert_path):\n",
    "    SEQ_LEN = seq_length\n",
    "\n",
    "\n",
    "    pretrained_path = bert_path\n",
    "    config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "    checkpoint_path = os.path.join(pretrained_path, 'model.ckpt-150000')\n",
    "    vocab_path = os.path.join(pretrained_path, 'vocab.txt')\n",
    "\n",
    "    model_bert = load_trained_model_from_checkpoint(\n",
    "          config_path,\n",
    "          checkpoint_path,\n",
    "          training=True,\n",
    "          trainable=True,\n",
    "          seq_len=SEQ_LEN,\n",
    "      )\n",
    "\n",
    "# we will take the pretrained model till \"NSP-Dense\" Layer\n",
    "    inputs = model_bert.inputs[:2]\n",
    "    dense = model_bert.get_layer('NSP-Dense').output    \n",
    "    model_txt= Model(inputs=inputs,outputs=dense)\n",
    "    \n",
    "    return model_txt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
