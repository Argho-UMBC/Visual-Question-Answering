{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder,LabelBinarizer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.layers import Input, Dense, Activation, Dropout, LSTM, Flatten, Embedding, merge,TimeDistributed,concatenate,Bidirectional,Reshape\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################################################################################################\n",
    "\n",
    "# Text file contains three information. Image ID, Question and Answer. So I want to separate all those three components by separate function.\n",
    "# for example, \"synpic41148|what kind of image is this?|cta - ct angiography\". Here, synpic41148-is Image ID, what kind of image is this?- is the question and ct angiography- is the answer. \n",
    "# Separate function will store these three imformation separately.\n",
    "\n",
    "\n",
    "\n",
    "def separate(Text_file_name_location): \n",
    "    \n",
    "    # create null vector to store image id, question and answer \n",
    "    \n",
    "    length=len(open(Text_file_name_location,\"r\").read().split(\"\\n\"))\n",
    "    question=[] \n",
    "    img_id=[]\n",
    "    answer=[]\n",
    "    img_jpg=[]\n",
    "    ques_no_punc=[]\n",
    "    \n",
    "    for line in range(length):   # there are in total 3827 instances (train+valid+test)\n",
    "        data=open(Text_file_name_location)\n",
    "        split_ques=data.read().split(\"\\n\")[line]      # split each line\n",
    "        ques=split_ques.split(\"|\")                 # from each line split image id, question and answer \n",
    "        question.append(\" \".join(ques[1].split()).lower())           # convert all answers and question in lower case\n",
    "        answer.append(\" \".join(ques[2].split()).lower())\n",
    "        img_id.append(ques[0].lower())\n",
    "\n",
    "\n",
    "    answer_final=[]\n",
    "    \n",
    "    for ans in range(length):\n",
    "            y=answer[ans]        \n",
    "            answer_final.append(y.translate(str.maketrans(\"\",\"\", string.punctuation)))   ### remove the punctuation mark from answer\n",
    "    \n",
    "\n",
    "    for ques in range(length):\n",
    "        z=question[ques]        \n",
    "        ques_no_punc.append(z.translate(str.maketrans(\"\",\"\", string.punctuation)))  # remove the punctuation mark from question\n",
    "   \n",
    "\n",
    "    for img in range(length):  ## we add .jpg extention with all image id so that we call call then later\n",
    "        x=img_id[img]+\".jpg\"\n",
    "        img_jpg.append(x)\n",
    "         \n",
    "    \n",
    "    \n",
    "    dictionary=dict()    \n",
    "\n",
    "    dictionary[\"Question\"]=ques_no_punc  # save those image id , question and answer as a dictionary\n",
    "    dictionary[\"Image_id\"]=img_jpg\n",
    "    dictionary[\"Answer\"]=answer_final\n",
    "    \n",
    "      \n",
    "    return dictionary  # this dictionary contains all information \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "\n",
    "# Image file has three part, namely, Training, Validation and testing. \n",
    "# Training folder has 3200 Images, Validation floder has 500 Images and Testing has 125 Images.\n",
    "\n",
    "# image_presprocess_modality function resize all the images into (224,224,3)\n",
    "\n",
    "\n",
    "# sequence of image from main image file and from question file is different\n",
    "# sequence of image_id_list should be according to text file (question text file). That's we need to provide image_id_list\n",
    "\n",
    "# image pre-process involves the process to resize the each image into (224,224,2) shape\n",
    "\n",
    "def image_preprocess(folder_location,image_id_list): \n",
    "\n",
    "    #     img_path_train=folder_location\n",
    "    \n",
    "    image_id=image_id_list\n",
    "    reshaped_image=[]  \n",
    "    \n",
    "    for img in range(len(image_id)):\n",
    "        join_path=os.path.join(folder_location,image_id[img])\n",
    "        im=cv2.imread(join_path)\n",
    "        re=cv2.resize(im,(224,224))\n",
    "        reshaped_image.append(re)\n",
    "   \n",
    "    reshaped_image=np.array(reshaped_image)\n",
    "\n",
    "    return reshaped_image\n",
    "\n",
    "\n",
    "######################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "## Here we convert all answer into both integer label and one-hot-encoding\n",
    "\n",
    "# we want \n",
    "\n",
    "# reference_label-----> according to this label we want to fit the label\n",
    "# target_label--------> on which we want to transform\n",
    "\n",
    "\n",
    "\n",
    "class LabelPreprocess:\n",
    "    \n",
    "    def __init__(self,target_label,reference_label):\n",
    "        \n",
    "        self.target_label=target_label\n",
    "        self.reference_label=reference_label\n",
    "    \n",
    "    def integer_encoding(target_label,reference_label):\n",
    "\n",
    "        y_array=np.array(reference_label)\n",
    "        label_encoder = LabelEncoder()\n",
    "        integer_encoded = label_encoder.fit(y_array)\n",
    "#         target_label= target_label.map(lambda s: '<unknown>' if s not in label_encoder.classes_ else s)\n",
    "        label_encoder.classes_ = np.append(integer_encoded.classes_, 'zero') ##### \"zero\" for umknown label\n",
    "        integer_encoded1 = label_encoder.transform(target_label)\n",
    "\n",
    "        return integer_encoded1\n",
    "\n",
    "                          \n",
    "                          \n",
    "    def onehot_encoding(target_label,reference_label):\n",
    "        y_array=np.array(reference_label)\n",
    "        label_encoder = LabelEncoder()\n",
    "        integer_encoded = label_encoder.fit(y_array)\n",
    "        label_encoder.classes_ = np.append(integer_encoded.classes_, 'zero')\n",
    "        integer_encoded1=label_encoder.transform(np.array(reference_label))\n",
    "        integer_encoded2= label_encoder.transform(np.array(target_label))\n",
    "        \n",
    "\n",
    "        onehot_encoder = OneHotEncoder(sparse=False)\n",
    "        integer_encoded1 = integer_encoded1.reshape(len(integer_encoded1), 1)\n",
    "        integer_encoded2 = integer_encoded2.reshape(len(integer_encoded2), 1)\n",
    "\n",
    "        onehot_encoded = onehot_encoder.fit(integer_encoded1)\n",
    "\n",
    "        onehot_encoded1=onehot_encoder.transform(integer_encoded2)\n",
    "        \n",
    "        return onehot_encoded1\n",
    "    \n",
    "    \n",
    "#############################################################################################################################\n",
    "\n",
    "## question (sentence) pre-process for LSTM MODEL\n",
    "\n",
    "# reference_question-----> according to this label we want to fit the label\n",
    "# target_question--------> on which we want to transform\n",
    "\n",
    "class QuestionPreprocess:\n",
    "    \n",
    "    \n",
    "    def tokenize_question(question):    #### Tokenizr the question\n",
    "        \n",
    "        token=Tokenizer(oov_token=\"unk\")\n",
    "        token.fit_on_texts(question)\n",
    "\n",
    "        word_index=token.word_index\n",
    "        word_index\n",
    "        return word_index \n",
    "    \n",
    "    def sequence_question(target_question,reference_question):  #### convert the question into sequence\n",
    "        token=Tokenizer(oov_token=\"unk\")\n",
    "        token.fit_on_texts(reference_question)                     # tokenize will work on train data\n",
    "        seq_question=token.texts_to_sequences(target_question)\n",
    "        return seq_question                         # return list of question. each question now represented by integer token\n",
    "    \n",
    "    def padding_question(sequence_of_the_question,maxlength,padding_criterion): ## Padding criterion to make each question equal length\n",
    "        \n",
    "        pad_ques=pad_sequences(sequence_of_the_question,maxlen=maxlength,padding=padding_criterion)\n",
    "        return pad_ques\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "## question (sentence) pre-process for BERT MODEL\n",
    "\n",
    "# '/home/local/AD/asarkar2/BERT'\n",
    "\n",
    "# bert_path-----> location for bert folder where all files for pretrained bert, namely 'bert_config.json', 'model.ckpt-150000', 'vocab.txt' are stored\n",
    "\n",
    "def bert_question_preprocess(question_seq_length,bert_path,question):  ### we will insert all question (train+valid+test)\n",
    "    \n",
    "    SEQ_LEN = question_seq_length\n",
    "    all_ques=question\n",
    "\n",
    "    pretrained_path = bert_path \n",
    "    config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "    checkpoint_path = os.path.join(pretrained_path, 'model.ckpt-150000')\n",
    "    vocab_path = os.path.join(pretrained_path, 'vocab.txt')\n",
    "\n",
    "    model_bert = load_trained_model_from_checkpoint(\n",
    "          config_path,\n",
    "          checkpoint_path,\n",
    "          training=True,\n",
    "          trainable=True,\n",
    "          seq_len=SEQ_LEN,\n",
    "      )\n",
    "\n",
    "    token_dict = {}\n",
    "    with codecs.open(vocab_path, 'r', 'utf8') as reader:\n",
    "        for line in reader:\n",
    "            token = line.strip()\n",
    "            token_dict[token] = len(token_dict)\n",
    "\n",
    "    tokenizer = k_Tokenizer(token_dict)\n",
    "\n",
    "    token=[]  #### store the tokenized sentence\n",
    "    segment=[]\n",
    "       \n",
    "    for q in range(len(all_ques)):\n",
    "        ques=all_ques[q]\n",
    "        ids, segments = tokenizer.encode(ques, max_len=SEQ_LEN)\n",
    "        token.append(ids)\n",
    "        segment.append(segments)\n",
    "    \n",
    "    ### seperate train, valid and test question\n",
    "    \n",
    "\n",
    "    token_train=np.array(token[:3200])\n",
    "    token_valid=np.array(token[3200:3700])\n",
    "    token_test=np.array(token[3700:])\n",
    "\n",
    "\n",
    "    train_x=[token_train, np.zeros_like(token_train)]\n",
    "    valid_x=[token_valid, np.zeros_like(token_valid)]\n",
    "    test_x=[token_test, np.zeros_like(token_test)]\n",
    "\n",
    "\n",
    "    return train_x,valid_x,test_x   ## return all training, validation and text question\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
